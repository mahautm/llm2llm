lamorel_args:
  log_level: info
  allow_subgraph_use_whith_gradient: true
  distributed_setup_args:
    n_rl_processes: 1
    n_llm_processes: 1
  accelerate_args:
    config_file: /homedtcl/mmahaut/projects/llm2llm/PPO_finetuning/accelerate/default_accelerate.yaml
    machine_rank: 0
    num_machines: 1
  llm_args:
    model_type: causal
    model_path: facebook/opt-350m
    pretrained: true
    minibatch_size: 1
    parallelism:
      use_gpu: true
      model_parallelism_size: 1
      synchronize_gpus_after_scoring: false
      empty_cuda_cache_after_scoring: false
  updater_args:
rl_script_args:
  path: /homedtcl/mmahaut/projects/lamorel/zoo/llm2llm/train.py
  dataset_path: /shared_dir/llm2llm/data/boring_garden_randomized_train.txt
  valid_dataset_path: /shared_dir/llm2llm/data/boring_garden_randomized_valid.txt
  epochs: 10000
  validation_interval: 100
  steps_per_epoch: 2
  batch_size: 10
  max_new_tokens: 30
  ppo_updates: 10
  lam: 0.99
  gamma: 0.9
  clip_ratio: 0.2
  top_k: 10
  kl_loss_coeff: 0
  max_ep_len: 3
  lr: 1.0e-05
  lr_warmup_steps: 2000
  lr_warmup_max: 1
  lr_warmup_min: 0
  lora_r: 8
  score_coef: 0.1
  cur_coef: 0
  cur2_coef: 0.5
  ce_coef: 0.1
  entropy_loss_coef: 0
  value_loss_coef: 0
  clip_eps: 0.1
  save_freq: 100
  cohere_key: false
  affix_num_steps: null
  affixes: null
  log_dir: fine_tune
  log_file: fine_tune/diaLogOPT.txt
