lamorel_args:
  log_level: info
  allow_subgraph_use_whith_gradient: true
  distributed_setup_args:
    n_rl_processes: 1
    n_llm_processes: 1
  accelerate_args:
    config_file: /homedtcl/mmahaut/projects/llm2llm/PPO_finetuning/accelerate/default_accelerate.yaml
    machine_rank: 0
    num_machines: 1
  llm_args:
    model_type: causal
    model_path: facebook/opt-6.7b
    pretrained: true
    minibatch_size: 1
    parallelism:
      use_gpu: true
      model_parallelism_size: 5
      synchronize_gpus_after_scoring: false
      empty_cuda_cache_after_scoring: false
  updater_args:
rl_script_args:
  path: /homedtcl/mmahaut/projects/lamorel/zoo/llm2llm/train.py
  dataset_path: /homedtcl/mmahaut/projects/llm2llm/data/mindless_dataset_randomized_train.txt
  epochs: 500
  steps_per_epoch: 2
  batch_size: 10
  max_new_tokens: 30
  ppo_epochs: 2
  lam: 0.99
  gamma: 0.99
  clip_ration: 0.2
  target_kl: 0.01
  max_ep_len: 3
  lr: 1e-8
  lr_warmup_steps: 500
  lr_warmup_max: 0.001
  lr_warmup_min: 0
  lora_r: 8
  score_coef: 0.1
  cur_coef: 0.1
  cur2_coef: 0.5
  ce_coef: 0.1
  entropy_loss_coef: 0.1
  value_loss_coef: 0.1
  clip_eps: 0.1
  save_freq: 100
  cohere_key: false
  affixes:
    - 
      - "How many fruit does the other network have? I don't know, I must ask it: How many fruit do you have?\n"
      - ""
    -
      - ""
      - ""
      - ""
  log_dir: /homedtcl/mmahaut/projects/llm2llm/fine_tune
  log_file: /homedtcl/mmahaut/projects/llm2llm/fine_tune/diaLogOPT.txt
